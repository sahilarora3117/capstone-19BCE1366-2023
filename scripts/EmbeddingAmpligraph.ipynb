{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeb8acd6-eb58-4800-9cf3-ed5ee8dff3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e62e80f0-e0f7-441b-a6de-097ec8dee411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ampligraph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from ampligraph.datasets import load_fb15k_237\n",
    "from ampligraph.evaluation import train_test_split_no_unseen, evaluate_performance, mr_score, mrr_score, hits_at_n_score\n",
    "from ampligraph.discovery import query_topn, discover_facts, find_clusters\n",
    "from ampligraph.latent_features import TransE, ComplEx, HolE, DistMult, ConvE, ConvKB\n",
    "from ampligraph.utils import save_model, restore_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27a24e50-7932-4142-b573-79b1f24423af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5484/3180663522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from ampligraph.discovery import find_clusters\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02945f31-6fc4-4f60-bd9d-3bbf1d086535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ampligraph version: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "def display_aggregate_metrics(ranks):\n",
    "    print('Mean Rank:', mr_score(ranks)) \n",
    "    print('Mean Reciprocal Rank:', mrr_score(ranks)) \n",
    "    print('Hits@1:', hits_at_n_score(ranks, 1))\n",
    "    print('Hits@10:', hits_at_n_score(ranks, 10))\n",
    "    print('Hits@100:', hits_at_n_score(ranks, 100))\n",
    "\n",
    "print('Ampligraph version: {}'.format(ampligraph.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69d337f1-324d-4c6d-9d7f-5ffe897aa960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_start</th>\n",
       "      <th>_type</th>\n",
       "      <th>_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _start      _type  _end\n",
       "0    8627  HAS_ROUTE  8629\n",
       "1    8627  HAS_ROUTE  8630\n",
       "2    8627  HAS_ROUTE  8631\n",
       "3    8627  HAS_ROUTE  8632\n",
       "4    8627  HAS_ROUTE  8633\n",
       "5    8627  HAS_ROUTE  8634\n",
       "6    8627  HAS_ROUTE  8635\n",
       "7    8627  HAS_ROUTE  8636\n",
       "8    8627  HAS_ROUTE  8637\n",
       "9    8627  HAS_ROUTE  8638"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_new = pd.read_csv(\"../data/routes.csv\")\n",
    "dataset_new.columns = ['_start', '_end', '_type','_distance']\n",
    "dataset_new = dataset_new.reindex(columns=['_start', '_type', '_end', '_distance'])\n",
    "dataset_new.drop(dataset_new.index[dataset_new['_start'] == '_start'], inplace=True)\n",
    "dataset_new.drop(columns=['_distance'], inplace=True)\n",
    "dataset_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b7c94c2-e1b5-47bd-a51a-943af1553fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_to_id ,rel_to_idx = ampligraph.evaluation.create_mappings(dataset_new.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49d40684-9c7b-48d5-ab89-e8a4796a9f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    2],\n",
       "       [   0,    0,    3],\n",
       "       [   0,    0,    4],\n",
       "       ...,\n",
       "       [8386,    4, 8623],\n",
       "       [8387,    4, 8622],\n",
       "       [8388,    4, 8622]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ampligraph.evaluation.to_idx(dataset_new.to_numpy(), rel_to_idx, ent_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bb5ca44-01da-45fd-9c7e-9df98b7411fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples in the KG: (73954, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Total triples in the KG:', dataset_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33df7be6-095d-4891-900a-c72c8afa2045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples: (73954, 3)\n",
      "Size of train: (70954, 3)\n",
      "Size of valid: (1000, 3)\n",
      "Size of test: (2000, 3)\n"
     ]
    }
   ],
   "source": [
    "from ampligraph.evaluation import train_test_split_no_unseen\n",
    "# get the validation set of size 500\n",
    "test_train, X_valid = train_test_split_no_unseen(dataset_new.values, 1000, seed=0)\n",
    "\n",
    "# get the test set of size 1000 from the remaining triples\n",
    "X_train, X_test = train_test_split_no_unseen(test_train, 2000, seed=0)\n",
    "\n",
    "print('Total triples:', dataset_new.shape)\n",
    "print('Size of train:', X_train.shape)\n",
    "print('Size of valid:', X_valid.shape)\n",
    "print('Size of test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76d76ab7-0921-4f3a-a2b8-296d4c725dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average TransE Loss:   0.023726: 100%|███████████████████████████████████| 300/300 [02:24<00:00,  2.08epoch/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 2000/2000 [00:26<00:00, 75.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank: 163.081\n",
      "Mean Reciprocal Rank: 0.18552176422303676\n",
      "Hits@1: 0.0005\n",
      "Hits@10: 0.542\n",
      "Hits@100: 0.8315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = TransE(k=200,                                                             # embedding size\n",
    "               epochs=300,                                                        # Num of epochs\n",
    "               batches_count= 10,                                                 # Number of batches \n",
    "               eta=2,                                                             # number of corruptions to generate during training\n",
    "               loss='pairwise', loss_params={'margin': 1},                        # loss type and it's hyperparameters         \n",
    "               initializer='xavier', initializer_params={'uniform': False},       # initializer type and it's hyperparameters\n",
    "               regularizer='LP', regularizer_params= {'lambda': 0.001, 'p': 3},   # regularizer along with its hyperparameters\n",
    "               optimizer= 'adam', optimizer_params= {'lr': 0.001},                # optimizer to use along with its \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               \n",
    "               seed= 0, verbose=True)\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model, \n",
    "                             filter_triples=X_filter)\n",
    "\n",
    "save_model(model, 'Models_new/TransE.pkl')\n",
    "display_aggregate_metrics(ranks)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19d35f4e-6663-492d-82e6-c0bd291ab47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - All triples will be processed in the same batch (batches_count=1). When processing large graphs it is recommended to batch the input knowledge graph instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average ComplEx Loss:   0.110729: 100%|██████████████████████████████████| 300/300 [09:42<00:00,  1.94s/epoch]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 2000/2000 [01:56<00:00, 17.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank: 213.251\n",
      "Mean Reciprocal Rank: 0.2387062421129227\n",
      "Hits@1: 0.1735\n",
      "Hits@10: 0.3635\n",
      "Hits@100: 0.67525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = ComplEx(k=200, epochs=300, eta=1, loss='multiclass_nll', \n",
    "                initializer='xavier', initializer_params={'uniform': False},\n",
    "                regularizer='LP', regularizer_params= {'lambda': 0.0001, 'p': 3},\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                seed= 0, batches_count= 1, verbose=True)\n",
    "model.fit(X_train)\n",
    "\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model, \n",
    "                             filter_triples=X_filter)\n",
    "\n",
    "save_model(model, 'Models_new/ComplEx.pkl')\n",
    "display_aggregate_metrics(ranks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "521a04c9-f674-461b-a7cc-a33e361c0f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - All triples will be processed in the same batch (batches_count=1). When processing large graphs it is recommended to batch the input knowledge graph instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average DistMult Loss:   0.202328: 100%|█████████████████████████████████| 300/300 [01:51<00:00,  2.70epoch/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 2000/2000 [00:22<00:00, 87.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank: 230.1245\n",
      "Mean Reciprocal Rank: 0.2541328064527293\n",
      "Hits@1: 0.191\n",
      "Hits@10: 0.3725\n",
      "Hits@100: 0.65575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = DistMult(k=200, epochs=300, eta=1, loss='multiclass_nll', \n",
    "                initializer='xavier', initializer_params={'uniform': False},\n",
    "                regularizer='LP', regularizer_params= {'lambda': 0.0001, 'p': 3},\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                seed= 0, batches_count= 1, verbose=True)\n",
    "model.fit(X_train)\n",
    "\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model, \n",
    "                             filter_triples=X_filter)\n",
    "\n",
    "save_model(model, 'Models_new/DistMult.pkl')\n",
    "display_aggregate_metrics(ranks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ea55dd6-b3ef-4d6c-bd12-4acd1c3a8c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average ConvKB Loss:   0.031474: 100%|███████████████████████████████████| 100/100 [19:29<00:00, 11.70s/epoch]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 2000/2000 [25:24<00:00,  1.31it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Models_old/ConvKB.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5484/929718357.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                              filter_triples=X_filter)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Models_old/ConvKB.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdisplay_aggregate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ampligraph/lib/python3.7/site-packages/ampligraph/utils/model_utils.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, model_name_path, protocol)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mmodel_name_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEFAULT_MODEL_NAMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y_%m_%d-%H_%M_%S\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# dump model tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Models_old/ConvKB.pkl'"
     ]
    }
   ],
   "source": [
    "model = ConvKB(k=200, epochs=100, eta=1, loss='multiclass_nll', \n",
    "                initializer='xavier', initializer_params={'uniform': False},\n",
    "                regularizer='LP', regularizer_params= {'lambda': 0.0001, 'p': 3},\n",
    "                optimizer= 'adam', optimizer_params= {'lr': 0.001}, \n",
    "                seed= 0, \n",
    "                batches_count= 5, # Goes OOM (ResourceExhaustedError) if batch count is 1\n",
    "                verbose=True)\n",
    "model.fit(X_train)\n",
    "\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model, \n",
    "                             filter_triples=X_filter)\n",
    "\n",
    "save_model(model, 'Models_new/ConvKB.pkl')\n",
    "display_aggregate_metrics(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea99fa11-436f-4e9d-a40a-8a55b9bff36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank: 236.736\n",
      "Mean Reciprocal Rank: 0.22788252786336363\n",
      "Hits@1: 0.13525\n",
      "Hits@10: 0.405\n",
      "Hits@100: 0.74075\n"
     ]
    }
   ],
   "source": [
    "save_model(model, 'Models_new/ConvKB.pkl')\n",
    "display_aggregate_metrics(ranks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

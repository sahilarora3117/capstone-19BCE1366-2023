{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aeb8acd6-eb58-4800-9cf3-ed5ee8dff3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e62e80f0-e0f7-441b-a6de-097ec8dee411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ampligraph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from ampligraph.datasets import load_fb15k_237\n",
    "from ampligraph.evaluation import train_test_split_no_unseen, evaluate_performance, mr_score, mrr_score, hits_at_n_score\n",
    "from ampligraph.discovery import query_topn, discover_facts, find_clusters\n",
    "from ampligraph.latent_features import TransE, ComplEx, HolE, DistMult, ConvE, ConvKB\n",
    "from ampligraph.utils import save_model, restore_model\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27a24e50-7932-4142-b573-79b1f24423af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.discovery import find_clusters\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02945f31-6fc4-4f60-bd9d-3bbf1d086535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ampligraph version: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "def display_aggregate_metrics(ranks):\n",
    "    print('Mean Rank:', mr_score(ranks)) \n",
    "    print('Mean Reciprocal Rank:', mrr_score(ranks)) \n",
    "    print('Hits@1:', hits_at_n_score(ranks, 1))\n",
    "    print('Hits@10:', hits_at_n_score(ranks, 10))\n",
    "    print('Hits@100:', hits_at_n_score(ranks, 100))\n",
    "\n",
    "print('Ampligraph version: {}'.format(ampligraph.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "69d337f1-324d-4c6d-9d7f-5ffe897aa960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_start</th>\n",
       "      <th>_type</th>\n",
       "      <th>_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8627</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _start      _type  _end\n",
       "0    8627  HAS_ROUTE  8629\n",
       "1    8627  HAS_ROUTE  8630\n",
       "2    8627  HAS_ROUTE  8631\n",
       "3    8627  HAS_ROUTE  8632\n",
       "4    8627  HAS_ROUTE  8633\n",
       "5    8627  HAS_ROUTE  8634\n",
       "6    8627  HAS_ROUTE  8635\n",
       "7    8627  HAS_ROUTE  8636\n",
       "8    8627  HAS_ROUTE  8637\n",
       "9    8627  HAS_ROUTE  8638"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_new = pd.read_csv(\"../data/routes.csv\")\n",
    "dataset_new.columns = ['_start', '_end', '_type','_distance']\n",
    "dataset_new = dataset_new.reindex(columns=['_start', '_type', '_end', '_distance'])\n",
    "dataset_new.drop(dataset_new.index[dataset_new['_start'] == '_start'], inplace=True)\n",
    "dataset_new.drop(columns=['_distance'], inplace=True)\n",
    "dataset_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b7c94c2-e1b5-47bd-a51a-943af1553fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_to_id ,rel_to_idx = ampligraph.evaluation.create_mappings(dataset_new.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1704e6-cd17-44e4-996a-522f4d30aa8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49d40684-9c7b-48d5-ab89-e8a4796a9f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    2],\n",
       "       [   0,    0,    3],\n",
       "       [   0,    0,    4],\n",
       "       ...,\n",
       "       [8386,    4, 8623],\n",
       "       [8387,    4, 8622],\n",
       "       [8388,    4, 8622]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ampligraph.evaluation.to_idx(dataset_new.to_numpy(), rel_to_idx, ent_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c35c2d65-25b7-4959-aa5e-771657424258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import train_test_split_no_unseen\n",
    "def test_train_split(dataset):\n",
    "\n",
    "    test_train, X_valid = train_test_split_no_unseen(dataset.values, 1000, seed=0)\n",
    "    \n",
    "    X_train, X_test = train_test_split_no_unseen(test_train, 2000, seed=0)\n",
    "\n",
    "    print('Total triples:', dataset_new.shape)\n",
    "    print('Size of train:', X_train.shape)\n",
    "    print('Size of valid:', X_valid.shape)\n",
    "    print('Size of test:', X_test.shape)\n",
    "    return X_train, X_test, X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d71db6a-8856-4514-9cc1-52b4a6a0a4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples: (73954, 3)\n",
      "Size of train: (70954, 3)\n",
      "Size of valid: (1000, 3)\n",
      "Size of test: (2000, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_valid = test_train_split(dataset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5c15cbc5-4555-4130-88a8-893aed8a73c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9436, 'HAS_ROUTE', 9487],\n",
       "       [9567, 'HAS_ROUTE', 8637],\n",
       "       [16588, 'ON_CONTINENT', 17250],\n",
       "       ...,\n",
       "       [8809, 'HAS_ROUTE', 8640],\n",
       "       [13276, 'IN_REGION', 16136],\n",
       "       [8889, 'HAS_ROUTE', 8646]], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "213c5baf-fdfb-48e3-a888-81a130262a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(np.concatenate((X_test,X_valid)), columns = ['subject','predicate','object'])\n",
    "test_df.drop(columns=test_df.columns[0], axis=1,  inplace=True)\n",
    "test_df.to_csv(\"../data/testdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48e4016b-13e9-4317-b4d9-3255b5da14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_predicate(predicate, data_location, ret):\n",
    "    # get dataset\n",
    "    dataset = fetch_data(data_location)\n",
    "    \n",
    "    \n",
    "    data_with_predicate = dataset.loc[dataset['_type'] == predicate]\n",
    "    data_with_predicate.reset_index(inplace=True)\n",
    "    unique_objects = data_with_predicate.object.unique()\n",
    "    unique_subjects = data_with_predicate.subject.unique()\n",
    "    if (ret == \"sub\"):\n",
    "        return data_with_predicate, unique_subjects\n",
    "    if (ret == \"obj\"):\n",
    "        return data_with_predicate, unique_objects\n",
    "\n",
    "def find_top_score_item_from_pred(subject, predicate, data_location, model_location):\n",
    "    dataset = fetch_data(data_location)\n",
    "    model = restore_model(model_location)\n",
    "    \n",
    "    data_for_predicate = dataset.loc[dataset['_type'] == predicate]\n",
    "    unique_object = data_for_predicate.object.unique()\n",
    "    \n",
    "    hypothesis = np.column_stack([[subject] * len(unique_object), \n",
    "                              [predicate] * len(unique_object),\n",
    "                              unique_object,\n",
    "                             ])\n",
    "    triple_scores = model.predict(hypothesis);\n",
    "    scored_hypothesis = np.column_stack([hypothesis, triple_scores]);\n",
    "    scored_hypothesis = scored_hypothesis[np.argsort(scored_hypothesis[:, 3])];\n",
    "    max_score_obj = unique_object[np.where(triple_scores == max(triple_scores))[0]];\n",
    "    return scored_hypothesis[-1]\n",
    "\n",
    "def predict_obj(model ,pred, sub, top):\n",
    "    triples, scores = query_topn(model, top_n=top, \n",
    "                             head=sub, \n",
    "                             relation=pred, \n",
    "                             tail=None, \n",
    "                             ents_to_consider=None, \n",
    "                             rels_to_consider=None,\n",
    "                            );\n",
    "    return triples, scores\n",
    "\n",
    "def predict_sub(model ,pred, obj, top):\n",
    "    triples, scores = query_topn(model, top_n=top, \n",
    "                             head=None, \n",
    "                             relation=pred, \n",
    "                             tail=obj, \n",
    "                             ents_to_consider=None, \n",
    "                             rels_to_consider=None,\n",
    "                            );\n",
    "    return triples, scores\n",
    "\n",
    "def triple_in_og_data(data_location, triple):\n",
    "    dataset = fetch_data(data_location)\n",
    "    if (len(dataset.loc[(dataset['_start'] == triple[0]) & (dataset['_type'] == triple[1]) & (dataset['_end'] == triple[2])]) > 0 ):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def fetch_data(data_location):\n",
    "    dataset_new = pd.read_csv(\"../data/routes.csv\")\n",
    "    dataset_new.columns = ['_start', '_end', '_type','_distance']\n",
    "    dataset_new = dataset_new.reindex(columns=['_start', '_type', '_end', '_distance'])\n",
    "    dataset_new.drop(dataset_new.index[dataset_new['_start'] == '_start'], inplace=True)\n",
    "    dataset_new.drop(columns=['_distance'], inplace=True)\n",
    "    return dataset_new\n",
    "def test_train_split(dataset):\n",
    "    test_train, X_valid = train_test_split_no_unseen(dataset_new.values, 1000, seed=0)\n",
    "\n",
    "    X_train, X_test = train_test_split_no_unseen(test_train, 2000, seed=0)\n",
    "\n",
    "\n",
    "    print('Total triples:', dataset.shape)\n",
    "    print('Size of train:', X_train.shape)\n",
    "    print('Size of valid:', X_valid.shape)\n",
    "    print('Size of test:', X_test.shape)\n",
    "    return X_train, X_test, X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0c4a0703-3457-468b-ad97-bdd05b8a3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlation_test_data(model_location):\n",
    "    model = restore_model(model_location)\n",
    "\n",
    "    # dataset = fetch_data(data_location)\n",
    "\n",
    "    X_train, X_test, X_valid = test_train_split(dataset_new)\n",
    "    \n",
    "    data_to_test = pd.DataFrame(X_test, columns = ['_start', '_type', '_end'])\n",
    "    print(data_to_test)\n",
    "\n",
    "    # print(data_to_test)\n",
    "    uniuqe_predicate = data_to_test._type.unique()\n",
    "    \n",
    "    print(uniuqe_predicate)\n",
    "    for predicate in uniuqe_predicate:\n",
    "        correct_triplet = 0\n",
    "        data_for_predicate = data_to_test.loc[data_to_test['_type'] == predicate]\n",
    "        data_for_predicate.reset_index(inplace=True)\n",
    "\n",
    "        print()\n",
    "        print(\"\\n For Predicate: \" + predicate)\n",
    "        print(data_for_predicate)\n",
    "        r = 0\n",
    "        \n",
    "        for i in range(len(data_for_predicate)):\n",
    "            print(data_for_predicate.loc[i,\"_start\"])\n",
    "            triples, scores = query_topn(model, top_n=1, \n",
    "                                         head=9436, \n",
    "                                         relation=\"HAS_ROUTE\", \n",
    "                                         tail=None, \n",
    "                                         ents_to_consider=None, \n",
    "                                         rels_to_consider=None\n",
    "                                         )\n",
    "            # if (len(data_to_test.loc[(data_to_test['_start'] == triples[0]) & (data_to_test['_type'] == triples[1]) & (data_to_test['_end'] == triples[2])]) > 0 ):\n",
    "            #     correct_triplet += 1\n",
    "            break\n",
    "        # print(\"Correct Instances Found: \" + str(correct_triplet), end =\", \")\n",
    "        # print(\"Total Instance: \" + str(len(data_for_predicate)), end = \", \")\n",
    "        # print(\"Accuracy %: \" + str(correct_triplet / len(data_for_predicate) * 100))\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "538cde7c-9c5c-4539-8bb9-be2d0e98d068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples: (73954, 3)\n",
      "Size of train: (70954, 3)\n",
      "Size of valid: (1000, 3)\n",
      "Size of test: (2000, 3)\n",
      "     _start         _type   _end\n",
      "0      9436     HAS_ROUTE   9487\n",
      "1      9567     HAS_ROUTE   8637\n",
      "2     16588  ON_CONTINENT  17250\n",
      "3      9214     HAS_ROUTE   8642\n",
      "4      8748     HAS_ROUTE   8694\n",
      "...     ...           ...    ...\n",
      "1995  10764     HAS_ROUTE   9145\n",
      "1996   8820     HAS_ROUTE   8664\n",
      "1997   8809     HAS_ROUTE   8640\n",
      "1998  13276     IN_REGION  16136\n",
      "1999   8889     HAS_ROUTE   8646\n",
      "\n",
      "[2000 rows x 3 columns]\n",
      "['HAS_ROUTE' 'ON_CONTINENT' 'IN_COUNTRY' 'IN_REGION' 'IN_CITY']\n",
      "\n",
      "\n",
      " For Predicate: HAS_ROUTE\n",
      "      index _start      _type  _end\n",
      "0         0   9436  HAS_ROUTE  9487\n",
      "1         1   9567  HAS_ROUTE  8637\n",
      "2         3   9214  HAS_ROUTE  8642\n",
      "3         4   8748  HAS_ROUTE  8694\n",
      "4         5   8853  HAS_ROUTE  8640\n",
      "...     ...    ...        ...   ...\n",
      "1275   1994   9858  HAS_ROUTE  9093\n",
      "1276   1995  10764  HAS_ROUTE  9145\n",
      "1277   1996   8820  HAS_ROUTE  8664\n",
      "1278   1997   8809  HAS_ROUTE  8640\n",
      "1279   1999   8889  HAS_ROUTE  8646\n",
      "\n",
      "[1280 rows x 4 columns]\n",
      "9436\n",
      "ERROR - Input triples include one or more entities not present in the training set. Please filter all concepts in X that do not occur in the training test (set filter_unseen=True in evaluate_performance) or retrain the model on a training set that includes all the desired concept types.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input triples include one or more entities not present in the training set. Please filter all concepts in X that do not occur in the training test (set filter_unseen=True in evaluate_performance) or retrain the model on a training set that includes all the desired concept types.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15690/1067719535.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_correlation_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Models_new/TransE.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15690/1077634580.py\u001b[0m in \u001b[0;36mfind_correlation_test_data\u001b[0;34m(model_location)\u001b[0m\n\u001b[1;32m     30\u001b[0m                                          \u001b[0mtail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                          \u001b[0ments_to_consider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                                          \u001b[0mrels_to_consider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                                          )\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# if (len(data_to_test.loc[(data_to_test['_start'] == triples[0]) & (data_to_test['_type'] == triples[1]) & (data_to_test['_end'] == triples[2])]) > 0 ):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ampligraph/lib/python3.7/site-packages/ampligraph/discovery/discovery.py\u001b[0m in \u001b[0;36mquery_topn\u001b[0;34m(model, top_n, head, relation, tail, ents_to_consider, rels_to_consider)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;31m# Get scores for completed triples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;31m# Join triples and scores, sort ascending by scores, then take top_n results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ampligraph/lib/python3.7/site-packages/ampligraph/latent_features/models/TransE.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, from_idx)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalibrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_neg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_base_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ampligraph/lib/python3.7/site-packages/ampligraph/latent_features/models/EmbeddingModel.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, from_idx)\u001b[0m\n\u001b[1;32m   1727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdealing_with_large_graphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1729\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment_to_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ment_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_to_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1730\u001b[0m             \u001b[0mx_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ampligraph/lib/python3.7/site-packages/ampligraph/evaluation/protocol.py\u001b[0m in \u001b[0;36mto_idx\u001b[0;34m(X, ent_to_idx, rel_to_idx)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_to_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ampligraph/lib/python3.7/site-packages/ampligraph/evaluation/protocol.py\u001b[0m in \u001b[0;36m_convert_to_idx\u001b[0;34m(X, ent_to_idx, rel_to_idx, obj_to_idx)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0munseen_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munseen_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'concept_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'entities'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munseen_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munseen_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_idx_p\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input triples include one or more entities not present in the training set. Please filter all concepts in X that do not occur in the training test (set filter_unseen=True in evaluate_performance) or retrain the model on a training set that includes all the desired concept types."
     ]
    }
   ],
   "source": [
    "find_correlation_test_data(\"Models_new/TransE.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9695f9ad-f95f-4c6e-b4a0-120a52a905e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_start</th>\n",
       "      <th>_type</th>\n",
       "      <th>_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9436</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>9487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>9436</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>9436</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>11341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>9436</td>\n",
       "      <td>IN_CITY</td>\n",
       "      <td>12895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>9436</td>\n",
       "      <td>HAS_ROUTE</td>\n",
       "      <td>8911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _start      _type   _end\n",
       "0      9436  HAS_ROUTE   9487\n",
       "606    9436  HAS_ROUTE   8690\n",
       "1068   9436  HAS_ROUTE  11341\n",
       "1420   9436    IN_CITY  12895\n",
       "1964   9436  HAS_ROUTE   8911"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_train = pd.DataFrame(X_train, columns = ['_start', '_type', '_end'])\n",
    "data_to_test = pd.DataFrame(X_test, columns = ['_start', '_type', '_end'])\n",
    "data_to_test.loc[data_to_test['_start'] == 9436]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "76d76ab7-0921-4f3a-a2b8-296d4c725dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average TransE Loss:   0.023726: 100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [02:15<00:00,  2.21epoch/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:24<00:00, 81.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank: 163.081\n",
      "Mean Reciprocal Rank: 0.18552176422303676\n",
      "Hits@1: 0.0005\n",
      "Hits@10: 0.542\n",
      "Hits@100: 0.8315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = TransE(k=200,                                                             # embedding size\n",
    "               epochs=300,                                                        # Num of epochs\n",
    "               batches_count= 10,                                                 # Number of batches \n",
    "               eta=2,                                                             # number of corruptions to generate during training\n",
    "               loss='pairwise', loss_params={'margin': 1},                        # loss type and it's hyperparameters         \n",
    "               initializer='xavier', initializer_params={'uniform': False},       # initializer type and it's hyperparameters\n",
    "               regularizer='LP', regularizer_params= {'lambda': 0.001, 'p': 3},   # regularizer along with its hyperparameters\n",
    "               optimizer= 'adam', optimizer_params= {'lr': 0.001},                # optimizer to use along with its                \n",
    "               seed= 0, verbose=True)\n",
    "\n",
    "model.fit(X_train)\n",
    "\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model, \n",
    "                             filter_triples=X_filter, filter_unseen=True)\n",
    "\n",
    "save_model(model, 'Models_new/TransE.pkl')\n",
    "display_aggregate_metrics(ranks)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19d35f4e-6663-492d-82e6-c0bd291ab47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - All triples will be processed in the same batch (batches_count=1). When processing large graphs it is recommended to batch the input knowledge graph instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average ComplEx Loss:   0.110729: 100%|██████████████████████████████████| 300/300 [09:42<00:00,  1.94s/epoch]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 2000/2000 [01:56<00:00, 17.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank: 213.251\n",
      "Mean Reciprocal Rank: 0.2387062421129227\n",
      "Hits@1: 0.1735\n",
      "Hits@10: 0.3635\n",
      "Hits@100: 0.67525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = ComplEx(k=200, epochs=300, eta=1, loss='multiclass_nll', \n",
    "                initializer='xavier', initializer_params={'uniform': False},\n",
    "                regularizer='LP', regularizer_params= {'lambda': 0.0001, 'p': 3},\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                seed= 0, batches_count= 1, verbose=True)\n",
    "model.fit(X_train)\n",
    "\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model, \n",
    "                             filter_triples=X_filter)\n",
    "\n",
    "save_model(model, 'Models_new/ComplEx.pkl')\n",
    "display_aggregate_metrics(ranks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "521a04c9-f674-461b-a7cc-a33e361c0f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - All triples will be processed in the same batch (batches_count=1). When processing large graphs it is recommended to batch the input knowledge graph instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average DistMult Loss:   0.202328: 100%|█████████████████████████████████| 300/300 [01:51<00:00,  2.70epoch/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 2000/2000 [00:22<00:00, 87.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank: 230.1245\n",
      "Mean Reciprocal Rank: 0.2541328064527293\n",
      "Hits@1: 0.191\n",
      "Hits@10: 0.3725\n",
      "Hits@100: 0.65575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = DistMult(k=200, epochs=300, eta=1, loss='multiclass_nll', \n",
    "                initializer='xavier', initializer_params={'uniform': False},\n",
    "                regularizer='LP', regularizer_params= {'lambda': 0.0001, 'p': 3},\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                seed= 0, batches_count= 1, verbose=True)\n",
    "model.fit(X_train)\n",
    "\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model, \n",
    "                             filter_triples=X_filter)\n",
    "\n",
    "save_model(model, 'Models_new/DistMult.pkl')\n",
    "display_aggregate_metrics(ranks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ea55dd6-b3ef-4d6c-bd12-4acd1c3a8c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average ConvKB Loss:   0.031474: 100%|███████████████████████████████████| 100/100 [19:29<00:00, 11.70s/epoch]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 2000/2000 [25:24<00:00,  1.31it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Models_old/ConvKB.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5484/929718357.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                              filter_triples=X_filter)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Models_old/ConvKB.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdisplay_aggregate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ampligraph/lib/python3.7/site-packages/ampligraph/utils/model_utils.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, model_name_path, protocol)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mmodel_name_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEFAULT_MODEL_NAMES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y_%m_%d-%H_%M_%S\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# dump model tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Models_old/ConvKB.pkl'"
     ]
    }
   ],
   "source": [
    "model = ConvKB(k=200, epochs=100, eta=1, loss='multiclass_nll', \n",
    "                initializer='xavier', initializer_params={'uniform': False},\n",
    "                regularizer='LP', regularizer_params= {'lambda': 0.0001, 'p': 3},\n",
    "                optimizer= 'adam', optimizer_params= {'lr': 0.001}, \n",
    "                seed= 0, \n",
    "                batches_count= 5, # Goes OOM (ResourceExhaustedError) if batch count is 1\n",
    "                verbose=True)\n",
    "model.fit(X_train)\n",
    "\n",
    "X_filter = np.concatenate([X_train, X_valid, X_test], 0)\n",
    "\n",
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model, \n",
    "                             filter_triples=X_filter)\n",
    "\n",
    "save_model(model, 'Models_new/ConvKB.pkl')\n",
    "display_aggregate_metrics(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea99fa11-436f-4e9d-a40a-8a55b9bff36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rank: 236.736\n",
      "Mean Reciprocal Rank: 0.22788252786336363\n",
      "Hits@1: 0.13525\n",
      "Hits@10: 0.405\n",
      "Hits@100: 0.74075\n"
     ]
    }
   ],
   "source": [
    "save_model(model, 'Models_new/ConvKB.pkl')\n",
    "display_aggregate_metrics(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdfe98a-d6c9-4d4a-9570-032d5369f957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6aab8366-cde7-47f1-9d28-0e47c793cfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total triples: (73954, 3)\n",
      "Size of train: (70954, 3)\n",
      "Size of valid: (1000, 3)\n",
      "Size of test: (2000, 3)\n",
      "     _start         _type   _end\n",
      "0      9436     HAS_ROUTE   9487\n",
      "1      9567     HAS_ROUTE   8637\n",
      "2     16588  ON_CONTINENT  17250\n",
      "3      9214     HAS_ROUTE   8642\n",
      "4      8748     HAS_ROUTE   8694\n",
      "...     ...           ...    ...\n",
      "1995  10764     HAS_ROUTE   9145\n",
      "1996   8820     HAS_ROUTE   8664\n",
      "1997   8809     HAS_ROUTE   8640\n",
      "1998  13276     IN_REGION  16136\n",
      "1999   8889     HAS_ROUTE   8646\n",
      "\n",
      "[2000 rows x 3 columns]\n",
      "['HAS_ROUTE' 'ON_CONTINENT' 'IN_COUNTRY' 'IN_REGION' 'IN_CITY']\n",
      "     _start      _type  _end\n",
      "0      9436  HAS_ROUTE  9487\n",
      "1      9567  HAS_ROUTE  8637\n",
      "3      9214  HAS_ROUTE  8642\n",
      "4      8748  HAS_ROUTE  8694\n",
      "5      8853  HAS_ROUTE  8640\n",
      "...     ...        ...   ...\n",
      "1994   9858  HAS_ROUTE  9093\n",
      "1995  10764  HAS_ROUTE  9145\n",
      "1996   8820  HAS_ROUTE  8664\n",
      "1997   8809  HAS_ROUTE  8640\n",
      "1999   8889  HAS_ROUTE  8646\n",
      "\n",
      "[1280 rows x 3 columns]\n",
      "\n",
      "\n",
      " For Predicate: HAS_ROUTE\n",
      "     _start         _type   _end\n",
      "2     16588  ON_CONTINENT  17250\n",
      "9     12926  ON_CONTINENT  17252\n",
      "12     9185  ON_CONTINENT  17248\n",
      "15     9726  ON_CONTINENT  17248\n",
      "20    13670  ON_CONTINENT  17253\n",
      "...     ...           ...    ...\n",
      "1951  12577  ON_CONTINENT  17252\n",
      "1968  10694  ON_CONTINENT  17252\n",
      "1980  15002  ON_CONTINENT  17250\n",
      "1989  14562  ON_CONTINENT  17253\n",
      "1991  15359  ON_CONTINENT  17251\n",
      "\n",
      "[226 rows x 3 columns]\n",
      "\n",
      "\n",
      " For Predicate: ON_CONTINENT\n",
      "ERROR - Input triples include one or more entities not present in the training set. Please filter all concepts in X that do not occur in the training test (set filter_unseen=True in evaluate_performance) or retrain the model on a training set that includes all the desired concept types.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input triples include one or more entities not present in the training set. Please filter all concepts in X that do not occur in the training test (set filter_unseen=True in evaluate_performance) or retrain the model on a training set that includes all the desired concept types.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11972/2404021932.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_correlation_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/routes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Models_new/TransE.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_11972/1309587582.py\u001b[0m in \u001b[0;36mfind_correlation_test_data\u001b[0;34m(data_location, model_location)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_for_predicate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mtriples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_topn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_for_predicate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_start\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ments_to_consider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrels_to_consider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_start'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtriples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_to_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtriples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_to_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_end'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtriples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ampligraph/lib/python3.7/site-packages/ampligraph/discovery/discovery.py\u001b[0m in \u001b[0;36mquery_topn\u001b[0;34m(model, top_n, head, relation, tail, ents_to_consider, rels_to_consider)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;31m# Get scores for completed triples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;31m# Join triples and scores, sort ascending by scores, then take top_n results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ampligraph/lib/python3.7/site-packages/ampligraph/latent_features/models/TransE.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, from_idx)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalibrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_neg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_base_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ampligraph/lib/python3.7/site-packages/ampligraph/latent_features/models/EmbeddingModel.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, from_idx)\u001b[0m\n\u001b[1;32m   1727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdealing_with_large_graphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1729\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment_to_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ment_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_to_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1730\u001b[0m             \u001b[0mx_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ampligraph/lib/python3.7/site-packages/ampligraph/evaluation/protocol.py\u001b[0m in \u001b[0;36mto_idx\u001b[0;34m(X, ent_to_idx, rel_to_idx)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_to_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ampligraph/lib/python3.7/site-packages/ampligraph/evaluation/protocol.py\u001b[0m in \u001b[0;36m_convert_to_idx\u001b[0;34m(X, ent_to_idx, rel_to_idx, obj_to_idx)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0munseen_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munseen_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'concept_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'entities'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munseen_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munseen_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_idx_p\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input triples include one or more entities not present in the training set. Please filter all concepts in X that do not occur in the training test (set filter_unseen=True in evaluate_performance) or retrain the model on a training set that includes all the desired concept types."
     ]
    }
   ],
   "source": [
    "find_correlation_test_data(\"../data/routes.csv\", \"Models_new/TransE.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b6f7d-bed5-47ac-a2a1-5c6691306b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
